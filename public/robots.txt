# Robots.txt for Logistics SPA
# This tells search engines how to crawl your website

User-agent: *
Allow: /

# Important pages for crawling
Allow: /services
Allow: /excursions  
Allow: /roadside-assistance
Allow: /offers/

# Block admin areas (if any)
Disallow: /admin/
Disallow: /_vite/
Disallow: /node_modules/

# Sitemap location (update the domain)
Sitemap: https://logistics-spa.by/sitemap.xml

# Crawl delay (optional - helps prevent server overload)
Crawl-delay: 1
